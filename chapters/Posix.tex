\chapter{POSIX}
\section{Implementing Periodic Tasks}
The pseudocode of a Periodic Task is:
\begin{lstlisting}[language=C]
    void *PeriodicTask(void *arg)
    {
        <initialization>;
        <start periodic timer, period = T>;
        while (condition)
        {
            <job body>;
            <wait next activation>;
        }
    }
\end{lstlisting}

The job body is outside of out control as well as the initialization since it is application dependent. Hence we will analyze the various way we can implement the \texttt{<start periodic timer>} and \texttt{<wait next activation>} section/function using timers and clocks.

\subsection{Using UNIX clock}

The idea is to use unix clocks to implement the \texttt{wait\_next\_activation} function using \texttt{usleep} (relative sleep).

In this naive implementation:
\begin{itemize}
    \item The program reads the current time
    \item The program computes the relative sleep
    \[\delta = \text{next activation time} - \text{current time}\]
    \item The program calls \texttt{usleep} for a value of $\delta$
\end{itemize}

\begin{lstlisting}[language=C]
    void wait_next_activation(void)
    {
        gettimeofday(&tv, NULL);
        d = nt - (tv.tv_sec * 1000000 + tv.tv_usec);
        nt += period;
        usleep(d);
    }
\end{lstlisting}

The problem with this implementation is that preemption can happen in \texttt{wait\_next\_activation} between \texttt{gettimeofday} and \texttt{usleep} resulting in an incorrect sleeping time of the task.

The solution is to call a function that implements a periodic behaviour.

\subsection{Using UNIX itimer}
Unix systems provide a system call for setting up a periodic timer.

\begin{lstlisting}[language=C]
    #include <sys/time.h>
    int setitimer (int which, const struct itimerval *value, struct itimerval *ovalue);
\end{lstlisting}
The first parameter of the system call is the type of interval timer to use. Three values are admissible:
\begin{itemize}
    \item \texttt{ITIMER\_REAL}: timer fires after a specified real time. \texttt{SIGALRM} is sent to the process.
    \item \texttt{ITEMER\_VIRTUAL}: timer fires after the process consumes a specified amount of time (process time). \texttt{SIGPROF} is sent to the process.
    \item \texttt{ITEMER\_PROF}: process time + system calls (both user and system time = profiling)
\end{itemize}

Hence \texttt{setitimer()} can be used to implement \texttt{<start periodic timer>}.

\begin{lstlisting}[language=C]
    #include <sys/time.h>  // setitimer()
    #include <signal.h>    // signal()
    #include <unistd.h>    // pause()

    #define wait_next_activation pause // pause till a signal is fired

    static void sighand(int s) {} // empty signal handler (need for signal())

    int start_periodic_timer(uint64_t offs, int period)
    {
        struct itimerval t;
        // offset
        t.it_value.tv_sec     = offs / 1000000;
        t.it_value.tv_usec    = offs % 1000000;
        // period
        t.it_interval.tv_sec  = period / 1000000;
        t.it_interval.tv_usec = period % 1000000;
        // register signal and specify signal handler
        signal(SIGALRM, sighand);

        return setitimer(ITIMER_REAL, &t, NULL);

    }
\end{lstlisting}

The problem with this implementation is that the \texttt{SIGALRM} generated is handled by an empty handler. An idea is to implement a better \texttt{wait\_next\_activation}: instead of pause, the function can wait a \texttt{SIGALRM}.


\begin{lstlisting}[language=C]
    #include <sys/time.h>  // setitimer()
    #include <signal.h>    // signal()

    static sigset_t sigset;

    static void wait_next_activation(void)
    {
        int dummy;
        sigwait(&sigset, &dummy); // wait for any signal in the set to be pending
    }

    int start_periodic_timer(uint64_t offs, int period)
    {
        struct itimerval t;
        // offset
        t.it_value.tv_sec     = offs / 1000000;
        t.it_value.tv_usec    = offs % 1000000;
        // period
        t.it_interval.tv_sec  = period / 1000000;
        t.it_interval.tv_usec = period % 1000000;
        // define set of signal that should be processed
        sigemptyset(&sigset);                  // exclude all the defined signals
        sigaddset(&sigset, SIGALRM);           // add SIGALRM to the signal set
        sigprocmask(SIG_BLOCK, &sigset, NULL); // block signals specified in sigset (required by sigwait)

        return setitimer(ITIMER_REAL, &t, NULL);
    }
\end{lstlisting}

The limitation of using UNIX timers is that only one real-time timer is available per process.

\subsection{POSIX timers}
POSIX offer multiple types of clocks (e.g. \texttt{CLOCK\_REALTIME} and \texttt{CLOCK\_MONOTONIC}). In addition, it is possible to set up multiple timers per process (each process can dynamically allocate and start timers).
A timer firing generates an asynchronous event which si configurable by the program.

\begin{lstlisting}[language=C]
    #include <time.h> // timer_create()
    int timer_create(clockid_t clockid, struct sigevent *sevp, timer_t* timerid);
\end{lstlisting}
\begin{itemize}
    \item \texttt{clockid} specifies the clock that the new timer uses to measure time.
    \item \texttt{sevp} points to a \texttt{sigevent} structure that specifies how the caller should be notified when the timer expires
    \item \texttt{timerid} id of the new timer returned by the system call.
\end{itemize}

\begin{lstlisting}[language=C]
    #include <time.h> // timer_settime()
    int timer_settime(timer_t timerid, int flags, const struct itimerspec*v, struct itimerspec *ov);
\end{lstlisting}
\begin{itemize}
    \item \texttt{timerid} timer id
    \item \texttt{flags}: (use 0 = \texttt{TIMER\_ABSTIME})
    \item \texttt{v}: interval timer specifications (timer offset \texttt{it\_value}, timer period \texttt{it\_interval})
    \item \texttt{ov}: just set this to NULL... you wont need it trust me
\end{itemize}

Since we are using POSIX we need to link agains \texttt{librt} hence when compiling link the executable using the compiler flag \texttt{-lrt}.

With this new timer the implementation of \texttt{start\_periodic\_timer} becomes
\begin{lstlisting}[language=C]
    #include <time.h>      // timer_create(), timer_settime
    #include <signal.h>    // signal()
    #include <string.h>    // memset()

    static sigset_t sigset;

    static void wait_next_activation(void)
    {
        int dummy;
        sigwait(&sigset, &dummy); // wait for any signal in the set to be pending
    }

    int start_periodic_timer(uint64_t offs, int period)
    {
        struct itimerspec t;
        struct sigevent sigev;
        timer_t timer;
        int res;
        const int signal = SIGALRM;
        // offset
        t.it_value.tv_sec     = offs / 1000000;
        t.it_value.tv_usec    = offs % 1000000;
        // period
        t.it_interval.tv_sec  = period / 1000000;
        t.it_interval.tv_usec = period % 1000000;
        // define set of signal that should be processed
        sigemptyset(&sigset);                  // exclude all the defined signals
        sigaddset(&sigset, SIGALRM);           // add SIGALRM to the signal set
        sigprocmask(SIG_BLOCK, &sigset, NULL); // block signals specified in sigset (required by sigwait)
        // specify the sigevent
        memset(&sigev, 0, sizeof(struct sigevent)); // empty sigevent structure
        sigev.sigev_notify = SIGEV_SIGNAL;
        sigev.sigev_signo = signal;
        // create timer
        res = timer_create(CLOCK_MONOTONIC, &sigev, &timer);
        // inizialize periodic timer with the specs in t
        return timer_settime(timer, TIMER_ABSTIME, &t, NULL);
    }
\end{lstlisting}

Still a process can still be preempted and the relative sleeping problem is still present in some form. The solution is to use Absolute Time from POSIX timers and clocks

\subsection{Using POSIX clock and timers with Absolute time}
Instead of reading the current time and computing $\delta$ based on it \texttt{wait\_next\_activation()} can directly wait for the absolute arrival time of the next job using a \texttt{clock\_nanosleep()} call.
\begin{lstlisting}[language=C]
    #include <time.h>
    int clock_nanosleep(clockid_t clock_id, int flags, const struct timespec *request, struct timespec *remain);
\end{lstlisting}
\begin{itemize}
    \item \texttt{clock\_id}: specifies the clock agains which the sleep interval is to be measured (\texttt{CLOCK\_REALTIME}, \texttt{CLOCK\_MONOTONIC}, \texttt{CLOCK\_PROCESS\_CPUTIME\_ID}).
    \item \texttt{flags}: if 0 then specified request is interval, if \texttt{TIMER\_ABSTIME} then specified request is an absolute time.
    \item \texttt{request} structure specifying time to wait
    \item \texttt{remain} (if not NULL) returns the remaining unslept time
\end{itemize}
\begin{lstlisting}[language=C]
    #include <time.h>
    clock_gettime(clockid_t clk_id, struct timespec* res);
\end{lstlisting}
\begin{itemize}
    \item \texttt{clock\_id}: specifies the clock agains which the sleep interval is to be measured (\texttt{CLOCK\_REALTIME}, \texttt{CLOCK\_MONOTONIC}, \texttt{CLOCK\_PROCESS\_CPUTIME\_ID}).
    \item \texttt{res} result of the clock reading
\end{itemize}

\begin{lstlisting}[language=C]
    #include <time.h>      // clock_gettime(), clock_nanosleep()

    static struct timespec r;
    static int period;

    static inline void timespec_add_us(struct timespec *t, uint64_t d){ ... } // add d to timespec t by converting to us to ns
    static void wait_next_activation(void)
    {
        clock_nanosleep(CLOCK_REALTIME, TIMER_ABSTIME, &r, NULL);
        timespec_add_us(&r, period)
    }

    int start_periodic_timer(uint64_t offs, int period)
    {
       clock_gettime(CLOCK_REALTIME, &r);
       timespec_add_us(&r, offs);
       period = t;
       return 0;
    }
\end{lstlisting}

Notice that r and period are global variable: this is a bad idea. Hence we wrap these two variables in a struct:
\begin{lstlisting}[language=C]
    struct periodic_task
    {
        struct timespec r;
        int period;
    }
\end{lstlisting}
Whenever a new periodic task is needed: inside \texttt{start\_periodic\_timer} periodic task is initialized and its values are passed to the aforementioned function calls.

\vfill
\textbetweendoublerules{Summary}
\begin{itemize}
    \item Unix allows 1 process to have $N$ timers and 1 thread can sleep until a future time point (only relative sleep)
    \item POSIX allows 1 timer for 1 thread (RT task) and avoids the relative-sleep problem
    \item POSIX guarantees \texttt{CLOCK\_REALTIME} exists, but it is not good for real time applications: may jump forward/backward and is prone to overflow: it cannot be restarted hence it will overflow on 32 bit machine in year 2038
    \item For these reasons, use \texttt{CLOCK\_MONOTONIC} whenever possible since it is not user settable, it is restarable when the system is restarted (use it in conjunction to \texttt{clock\_gettime()})
\end{itemize}

\section{Real-Time scheduling}
\subsection{Better Statistics}
First and foremost we need to improve the statistics for each task: since now we have considered the average time over 100 jobs as a statistics. However, this measurement may still yield a misleading result.

\example{$T=D=2$}{A task $\tau$ generates 101 jobs ranging from $J_1$ to $J_{101}$.\\
All but $J_2$ start at activation time and all but $J_1$ need 1 time units to complete.  $J_1$ however finishes 3 time units after activation (deadline miss).\\
The average time printed by $J_{101}$ is 2: 1 job every 2 time units. Through the fact that $J_1$ missed its deadline caused every other job to miss its deadline.
}
In other terms we need to introduce additional statistical quantities to verify which job if any miss their deadlines: namely jitter, best and worst case response times and consecutive deadline misses.

Given a job $J_{i,k}$ of a task $\tau_i$ we need to save the following quantities:
\begin{itemize}
    \item $k$: job number
    \item $s_{i,k}$: start time of the job
    \item $f_{i,k}$: finishing time of the job
    \item $t_0$: expected time of earliest task activation (initial offset of first job activation)
    \item For every task $\tau_i$ with offset $\Phi_i$, period $T_i$ and relative deadline $D_i$, compute the absolute activation time and absolute deadline:
    \[r_{i,k} = t_0 + \Phi_i + (k-1)T_i\qquad d_{i,k} = r_{i,k} + D_i\]
    Given these quantities we can define:
    \begin{itemize}
        \item A job $J_{i,k}$ does not miss its deadline if 
        \[r_{i,k}\le s_{i,k}\le f_{i,k} \le d_{i,k}\]
        \item Best and worst case response time
        \[\min_k{(f_{i,k} - r_{i,k})}\qquad \max_k{(f_{i,k} - r_{i,k})}\]
        \item Relative start time jitter
        \[\max_k \abs{(s_{i,k} - r_{i,k}) - (s_{i,k-1} - r_{i,k-1})}\]
        \item Absolute start time jitter
        \[\max_k \abs{s_{i,k} - r_{i,k}} - \min_k{(s_{i,k} - r_{i,k})}\]
        \item Relative finish time jitter
        \[\max_k \abs{(f_{i,k} - r_{i,k}) - (f_{i,k-1} - r_{i,k-1})}\]
        \item Absolute finish time jitter
        \[\max_k \abs{f_{i,k} - r_{i,k}} - \min_k{(f_{i,k} - r_{i,k})}\]
    \end{itemize}
\end{itemize}

These quantities can be measured using the \texttt{clock\_gettime()} in conjunction with \texttt{CLOCK\_MONOTONIC}, whereas $t_0$ can be computed using \texttt{timer\_settime()} with flag \texttt{TIMER\_ABSTIME}.\\
In addition to this the response time $R_{i,k}$ is equal to the execution time $c_{i,k}$ if and only if $r_{i,k}$ up to $f_{i,k}$ has no preemption/blocking, otherwise it holds that $R_{i,k} > c_{i,k}$.
To measure the execution time use \texttt{clock\_gettime()} with \texttt{CLOCK\_THREAD\_CPUTIME\_ID}.
In addition, since this measurement is affected by energy-saving mode we need to change the cpu scaling for each core in the machine:
\begin{lstlisting}[language=bash]
    cd /sys/devices/system/cpu/cpufreq
    cat policy?/scaling_{min,cur,max}_freq   # cat scaling_{min,cur,max}_freq content contained in each folder policy$character$
    for x in policy?; do
        sudo tee $x/scaling_min_freq < $x/scaling_max_freq; % for each core policy replace scaling_min_freq with scaling_max_freq
    done
    cat policy?/scaling_{min,cur,max}_freq   # cat scaling_{min,cur,max}_freq content contained in each folder policy$character$
\end{lstlisting}

\subsection{Real-Time Scheduling}
POSIX provides support for real-time scheduling: but NO multiprocessor parititoning and migration.\\
To provide this support for real time scheduling POSIX provides priority scheduling support:
\begin{itemize}
    \item Multiple priority levels
    \item A task queue per priority level
    \item Run first task fo highest-priority in non-empty queue
\end{itemize}
POSIX also provides multiple scheduling policies: a scheduling policy describes how tasks are moved between the prioririty queues. Please notice that these scheduling policies consider Fixed priority: task is always in the same priority queue.\\
Not all RT theory for uniprocessor (UP) is for MP. So we need to partition MP to have 1 processor as 1 UP.
In order to do so we add the following api calls:
\begin{lstlisting}[language=C]
    #define _GNU_SOURCE // CPU_ZERO(), CPU_SET(), sched_setaffinity()
    #include <sched.h>  // CPU_ZERO(), CPU_SET(), sched_setaffinity()

    void main(int argc, char**argv)
    {
        cpu_set_t cpumask;
        CPU_ZERO(&cpumask);         // clears cpumask, so that it contains no CPUs
        CPU_SET(0, &cpumask);       // Add CPU 0 to cpumask
        // sets the CPU affinity mask of the thread whose ID is pid (=0),
        // if pid is zero, then the calling thread is used.
        // it also has to provide the size of the cpuset pointed to by cpumask
        if (sched_setaffinity(0, sizeof(cpumask), &cpumask))
        {
            perror("sched_setaffinity failed");
            return -1;
        }
    }
\end{lstlisting}

POSIX specifically requires four scheduling policies:
\begin{itemize}
    \item \texttt{SCHED\_FIFO}: tasks with same priority level (in the same queue) are executed in a first in first out manner (this might lead to starvation of other tasks with same priority). Only higher priotiy tasks can preempt it
    \item \texttt{SCHED\_RR}: tasks with same priority level (in the same queue) are executed in a round robin fashion: a task executes for a \side{time/scheduling quantum} (fixed interval of time), than it is suspended and added to the back of the queue (tasks with the same priority are served fairly)
    \item \texttt{SCHED\_SPORADIC}: is a sporadic server that decreases the response times of aperiodic RT tasks
    \item \texttt{SCHED\_OTHER}: is the traditional Unix scheduler. It has dynamic priorities, and it is scheduled in background with respect to fixed priorities.
\end{itemize}

RR and FIFO priority values are comparable:
\begin{itemize}
    \item \texttt{sched\_get\_priority\_min(int \$policy\$)}: lowest priority value
    \item \texttt{sched\_get\_priority\_max(int \$policy\$)}: highest priority value
\end{itemize}

Hence the schduling policy can be set using the following API calls:
\begin{lstlisting}[language=C]
    #include <sched.h>  

    int sched_get_priority_min(int policy); // minimum priority value that can be used by the policy
    int sched_get_priority_max(int policy); // maximum priority value that can be used by the policy
    
    struct sched_param
    {
        ...
        int sched_priority;
        ...
    }
    /*
        @pid:    id of the thread (if 0 calling thread)
        @policy: scheduling policy
        @param:  value between min and max priority value (for SCHED_FIFO and SCHED_RR)
    */
    int sched_setscheduler(pid_t pid, int policy, const struct sched_param *param);
    
    /*
        @pid:    id of the thread (if 0 calling thread)
        @param:  value between min and max priority value 
    */
    int sched_setparam(pid_t pid, const struct sched_param *param);

\end{lstlisting}

If there is no swap to disk, no unlucky kernel latency, and MP has no unlycky bus contention, the scheduled RT tasks will have no deadline misses.\\
In general, "regular" (\texttt{SCHED\_OTHER}) tasks are scheduled in background relative to real-time tasks. A real-time task can preempt/starve other tasks.\\
Running applications with real-time priroities requires root privileges, hence after compiling perform this bash commands:
\begin{lstlisting}[language=bash]
    sudo chown root executable # change file owner to root
    sudo chmod u+s executable  # allow root to execute the executable (not the user)
\end{lstlisting}

\subsection{Memory Swapping}
The virtual memory mechanism can swap part of the process address space to disk: Memory swapping can increase execution times, resulting in temporal unpredictability, hence it is not good for real-time application.

A non-real time task can force a memory swap. To overcome this issue RT task can lock part of its address space in memory:
\begin{itemize}
    \item Locked memory cannot be swapped out of the physical memory disk
    \item This can result in a RAM exhaustion
\end{itemize}
Memory locking can be performed only by applications having root privileges.

\begin{lstlisting}[language=C]
    #include <sys/mman.h>

    // lock pages starting at @addr with size len (in bytes)
    int mlock(const void *addr, size_t len);
    // unlock pages starting at @addr with size len (in bytes)
    int munlock(const void *addr, size_t len);
    /*
        lock entire address space in memory
        MCL_CURRENT = current address space
        MCL_FUTURE  = all memory allocated in the future
        MCL_CURRENT | MCL_FUTURE = both
    */
    int mlockall(int flags);
\end{lstlisting}


\section{Concurrency}
A process implements the notion of \side{protection} in the sense that each process has its own address space and other private resources. A process can write/read in its address space but is not allowed to touch other processes' resources: two processes can share some resources for communication, but this has to be excplicitly allowed by them!

Processes usually communicate through message passing (e.g. pipes, sockets, signals,\dots).

A process is more than a set of private resources, it is an active entity.
The concept of process involves two aspects:
\begin{itemize}
    \item \side{Protection} or resource ownership
    \item \side{Execution}\\
    A process contains at least a schedulable entity, which can access the process's resources. As such it contains all the information for the scheduling (e.g. scheduling parameters).
    Furthermore this schedulable entity is also characterized by (at least) a CPU state and a stack.
\end{itemize}


Each single-threaded process has only one thread which involves:
\begin{itemize}
    \item One address space per process
    \item One stack per process
    \item One Process Control Block (PCB) per process
    \item Other private resources
    \item One single executino flow per process
\end{itemize}

This differs from a multi-threaded process in the sense that a process can have multiple threads in it:
\begin{itemize}
    \item One address space
    \item One PCB
    \item Multiple execution flows in a single process
    \item Multiple stacks (one per thread)
    \item One Thread Control Block (TCB) per thread
\end{itemize}

\subsection{Small Summary about Processes}
The Process Memory Layout involves three major components in its private address space: User memory, Stack and Heap.
In particular, the user memory is divided into three segments:
\begin{enumerate}
    \item Initialized data segment
    \item BSS (Block Started by Symbol): uninitialized global and static variables
    \item Text segment (containing the program code)
\end{enumerate}
The heap and the stack are straightforward to understand. However, the heap is usable through \texttt{malloc} and can grow using \texttt{brk()} and \texttt{sbrk()}

Each process is identified by a process ID (PID) which is unique in the system. Each time a process is created a PID is assigned to it. The value of the PID of a process can be retrieved using \texttt{getpid(void)}, whereas the PID of a process's creator (i.e. parent) can be retrieved using \texttt{getppid(void)}

\subsubsection{Fork}
A new process can be created using the api call \texttt{fork()}. The new process (called child process) contains a copy of the parent's address space. The call has one entry point and two exit points:
\begin{itemize}
    \item In the child, 0 is returned
    \item In the parent, the PID of the child is returned
\end{itemize}
In case of error fork returns a negative value is returned.

Generally speaking \texttt{fork()} is used in the following way:
\begin{lstlisting}[language=C]
    #include <sys/types.h> // pid_t
    #include <unistd.h>    // fork
    
    pid_t child_pid = fork();
    if(child_pid < 0) { return -1 }
    if(child_pid == 0)
        // child body
    else
        // parent body 
\end{lstlisting}
Alternatively:
\begin{lstlisting}[language=C]
    #include <sys/types.h> // pid_t
    #include <unistd.h>    // fork
    #include <stdlib.h>    // exit
    
    pid_t child_pid = fork();
    if(child_pid < 0) { return -1 }
    if(child_pid == 0)
    {
        // child body
        exit(0);
    }
    // parent body 
\end{lstlisting}

Since the child address space is a copy of the parent's: the child's text segment is the same as the parent's, consequently both the parent body and the child body must be in the same executable.

\subsubsection{Exec}
To avoid this one can use the \texttt{exec()} call or any of its variants.\\
Exec is a family of functions to replace the process address space (text, data and heap) (e.g. \texttt{execl()},\texttt{execlp()},\texttt{execle()},\texttt{execv()},\texttt{execvp()}).
The basic idea of exec is that it loads a new programme and jumps to it, but does not create a new process.

An example usage of exec is as follows:
\begin{lstlisting}[language=C]
    #include <sys/types.h> // pid_t
    #include <unistd.h>    // fork
    #include <stdio.h>     // perror
    
    pid_t child_pid = fork();
    if(child_pid < 0) { return -1 }
    if(child_pid == 0)
    {
        char *args[3] = {"arg1", "arg2", "arg3"};
        execve("child_body", args, NULL);
        perror("Execve"); // check if any error has occured
        return -1;
    }
    ...
\end{lstlisting}

Some non-posix compliant systems make no distinction between program and process and only provide a fork + exec combo. POSIX also provides a \texttt{system()} function which does fork + exec (+ wait)

A process terminates when:
\begin{enumerate}
    \item It invokes either the library call \texttt{exit()} or the system call \texttt{\_exit()}
    \item It returns from its main function
    \item It is killed by some external event (e.g. a signal)
\end{enumerate}

When it terminates explicity, a process can return a result to the parent.\\
Every process can register a hook ot be called on regular process termination 
\begin{lstlisting}[language=C]
    #include <stdlib.h>    // atexit
    
    int atexit(void (*function) (void));
\end{lstlisting}
However, please note that handlers are not called if exiting with \texttt{\_exit()}.

\subsubsection{Wait}
First form of synchronization between processes is waiting for a children to return to the parent.\\
A parent can wait for its child's termination using the api calls \texttt{wait()}, \texttt{waitpid()}, \texttt{wait4()}.
Formally:
\begin{lstlisting}[language=C]
    #include <sys/types.h>    // pid_t
    #include <sys/wait.h>     // wait()
    
    pid_t wait(int *status);
\end{lstlisting}
If the calling process has no children, \texttt{wait()} returns a value < 0\\
If at least there is one terminated child, \texttt{wait()} returns the child's exit value, and child's private resources are freed\\
If there are no terminated children, \texttt{wait()} blocks the calling process.

The other variants of the wait family of function allow to select the child to wait for.

Please note that after a process terminates, its private resources are not freed until its parent performs a \texttt{wait()}. Children processes that have terminated are said to be in a \side{zombie} state. Hence a good parent has to wait for its children to terminate.
When the parent of a process dies the process is reparented to \texttt{init} (a system process whose PID is 1). As a consequence, when a process dies all its zombies are eliminated.

A process can be notified about the termination of a child process through an asynchronous event (e.g. signal: \texttt{SIGCHLD})

\subsection{synchronization through Signals}
Concurrent processes interact in different ways: competition or cooperation.\\
Cooperation can be implemented through \side{signals}: Sometimes, a process has to wait until cooperating processes have completed some operation. In other terms, a process $\tau_i$ waits for an asynchronous event generated by: another process $\tau_j$ or the system.

\definition{Signal}{Asynchronous event directed to process $\tau$. Process $\tau$ can:
\begin{itemize}
    \item Wait for a signal
    \item Perform some other work in the meanwhile, and the signal will interrupt it.
\end{itemize}}

Signals are the software equivalent of interrupts. A process receiving a signal can:
\begin{itemize}
    \item Ignore it
    \item Interrupt its execution and jump to a \side{signal handler}
    \item Abort
\end{itemize}
A signal that has not caused one of the previous actions is a \side{pending signal}.

Signals are managed using a \side{signal table}. Such structure is a per process private resource that specifies how the process handles each signal. At process creation the signal table is initialized using default values.

The table entries can be modified using: \texttt{signal()} or \texttt{sigaction()}.
\begin{lstlisting}[language=C]
    #include <signal.h>
    /*
        @signum signal (e.g. SIGALRM)
        @handler either SIG_IGN, SIG_DFL or the address of a programmer-defined function
    */

    sighandler_t signal(int signum, sighandler_t handler);
    /*
        @signum signal (e.g. SIGALRM) excluding SIGKILL and SIGSTOP
        @act    the new action for signal signum
        @oldact old action for signal signum (if not null)
    */
    int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);
\end{lstlisting}

The prototype of a signal handler is very simple: it must return void and accept an integer value as input \texttt{void sighand(int n)}.
In order to set up a signal handler, we need to provide some of the parameters in a structure \texttt{sigaction} provided by the api.

\begin{lstlisting}[language=C]
struct sigaction {
    void     (*sa_handler)(int);
    void     (*sa_sigaction)(int, siginfo_t *, void *);
    sigset_t   sa_mask;
    int        sa_flags;
    void     (*sa_restorer)(void);
};
\end{lstlisting}
where:
\begin{itemize}
    \item \texttt{sa\_handler} is the signal handler (function), or \texttt{SIG\_DFL} (default action) or \texttt{SIG\_IGN} (ignore the signal)
    \item \texttt{sa\_mask} is a mask of signals to disable when the handler runs. This set can be modified using \texttt{sigemptyset()}, \texttt{sigfillset()}, \texttt{sigaddset()}, and \texttt{sigdelset()}
    \item Running handler cannot be interrupted by the handled signal again unless \texttt{SA\_NODEFER} is set in \texttt{sa\_flags}
\end{itemize}

A process can send a signal to other processes by using 
\begin{lstlisting}[language=C]
    int kill(pid_t pid, int sig)
\end{lstlisting}
Note that it must have the proper permissions: user root can send signals to every process, other users can send signals only to their own processes.
\texttt{kill} is not used only to kill a process: \texttt{kill -SIGALRM} does not kill a process, but \texttt{kill -SIGKILL} does.

A process can also send a signal to itself by 
\begin{lstlisting}[language=C]
    int raise(int sig);
\end{lstlisting}

\subsubsection{Signal Numbers}
Signals are identified by numbers and macros:
\begin{itemize}
    \item \texttt{SIGUSR1} and \texttt{SIGUSR1} are user defined signals
    \item \texttt{SIGALRM}, \texttt{SIGVTALRM}, and \texttt{SIGPROF} are used by process real-time, virtual and profiling timers
    \item \texttt{SIGKILL} is used to kill a program
    \item \texttt{SIGCHLD} is raised every time a child dies, or it is stopped, or it is resumed
    \item \texttt{SIGSTOP}, \texttt{SIGTSTP}, \texttt{SIGTTIN}, \texttt{SIGTTOU} stops a child
    \item \texttt{SIGCONT} resumes a child process
\end{itemize}

These last three signal numbers are useful for avoiding zombies:
\begin{itemize}
    \item The \texttt{SIGCHLD} handler can perform a \texttt{wait()}
    \item If \texttt{SIGCHLD} is ignored, zombies are not created
    \item Suppress \texttt{SIGCHLD} for stopped/resumed children by setting \texttt{SA\_NOCHLDSTOP} in \texttt{sa\_flags}
\end{itemize}

The main problem with signals are as follows:
\begin{itemize}
    \item Almost all of the signals are reserved for the system, only \texttt{SIGUSR} are free for user programs
    \item Signals can be lost: if a signal arrives more than once while it is blocked, it is not queued (it will fire only one time), this makes signals quite unreliable for RT IPC
    \item Signals do not transport information, only the signal number is available to the handler
\end{itemize}
The solution is to use POSIX Real-Time signals

\subsection{Real-Time signals}
Multiple pending RT signals are queued, not lost: the unblocked signal with a lower signo are delivered first. POSIX specifies no further ordering but Linux does.

Signals can transport information in the form of integers or pointers. For this reason the signal handler function prototype has an extended form:
\begin{lstlisting}[language=C]
    void sighand(int signum, siginfo_t *info, void *ignored);
\end{lstlisting}

As before such handler can be set using \texttt{sigaction}, with the only difference that:
\begin{itemize}
    \item instead of using \texttt{sa\_sighandler}, you must use \texttt{sa\_sigaction}
    \item You must use \texttt{SA\_SIGINFO} in \texttt{sa\_flags}.
\end{itemize}
This allows us to use a $M = SIGRTMAX - SIGRTMIN + 1$ signals for user app.
Instead of using \texttt{kill()} to send a message, now you should queue all the RT signal using \texttt{sigqueue()}

Real-Time signals carry information in \texttt{siginfo\_t}
\begin{lstlisting}[language=C]
    typedef struct
    {
        int si_signo;          // signal number
        int si_code;           // cause of the signal 
                               // kill() => SI_USER, 
                               // sigqueue() => SI_QUEUE
                               // posix timer => SI_TIMER
        union sigval si_value; // information carried by the signal
    } siginfo_t;

    union sigval
    {
        int sival_int;
        void *sival_ptr;
    }
\end{lstlisting}

The signal is queued as follows:
\begin{lstlisting}[language=C]
    #include <signal.h>

    int sigqueue(pid_t p, int n, const union sigval value);
\end{lstlisting}
\texttt{sigqueue()} returns < 0  in case of error, \texttt{EAGAIN} is returned if queue is full (no lost signal).

If no error occurs, queue signal $n$ to process $p$ and the information $value$ is transmitted with the signal.\\
The OS can generate RT signals, e.g., when POSIX async I/O is used to impplement future and promise.\\
For this reason we must specify the RT signal the OS shall generate by using the structure:
\begin{lstlisting}[language=C]
    struct sigevent
    {
        int sigev_notify;         // SIGEV_SIGNAL
        int sigev_signo;          // set this to the RT signal
        union sigval sigev_value; // information
        void (*sigev_notify_function)(union sigval);
        void *sigev_notify_attributes;
        pid_t sigev_notify_thread_id;
    };
\end{lstlisting}

POSIX's System Interfaces - Signal Actions says:
\begin{itemize}
    \item If the process is multi-threaded or
    \item If the process is single-threaded and a signal handler is executed other than as the result of either:
        \begin{itemize}
            \item The process calling \texttt{abort}, \texttt{raise}, \texttt{kill}, \texttt{pthread\_kill} or \texttt{sigqueue} to general a signal that is not blocked, or
            \item A pending signal being unblocked and being delivered before the call that unblocked it returns.
        \end{itemize}
\end{itemize}
Then any variable of static storage duration (global variable) used by signal handler should be limited to:
\begin{itemize}
    \item \texttt{errno} (if used, save and restore at start and finish)
    \item write (never read) \texttt{volatile sig\_atomic\_t} vars
\end{itemize}
And, any function called by handler should be limited to async-signal-safe function.

\section{POSIX Thread and their Real-Time Scheduling}
The POSIX standard is an IEEE standard specifying the OS interface. As such it is implemented by most Unix systems. The core concept of POSIX is that it defines a C API to handle concurrent activities and it distinguishes between processes and threads.\\
A thread is a schedulable entity (a flow of execution).\\
A process has one or more threads+ some private resources (address space, file table, \dots). So one thread is a single flow of control withing a process whereas a process has at least one thread (i.e. the main thread).

\subsection{Threads}
All threads in a process share the same address space, file table, program text, \dots. Each thread has it own context and its own stack. In each process there is a "special" thread (the main thread), which termination causes the termination of the process.

Therefore the question is: should we use processes or threads?\\
From a general point of view they both are an abstraction for parallelism, but processes are a protection boundary, whereas threads do not.
This means that a process sees no other process. However, IPC is usually costly for RT application and unsupportive of RT communication (e.g. Priority inheritance).

On the other hand a thread is not a protection boundary, in the sense that a thread can see other threads and their data (states). As such other threads can screw up another thread. However, threads do not have costrly IPC because communication is done by shared data. In addtion, threads support RT comunication such as Priority Inheritance and Highest Locking Priority protocols.


POSIX defines itw own threading library called \texttt{pthread} library which implements all primitive operations on threads (e.g. creation, termination, synchronization, \dots).
Threading primitives and data structures are contained in their separate headers (e.g. \texttt{sched.h},\texttt{pthread.h},\texttt{semaphore.h}).
Furthermore, in order to use this headers we must compire the program using the compiler flag \texttt{-pthread}.


The code executed by a thread (i.e. the \side{thread body}) is a C function of the form:
\begin{lstlisting}[language=C]
    void *thread_body(void *arg) { ... }
\end{lstlisting}
When created, a thread starts executing the first instruction of its body. The thread ends when exiting the body (at the end of the C function), but a thread can terminate also in other ways, such as by explicitly calling a termination function, when killed by another thread, \dots

A thread is created by invoking \texttt{pthread\_create()}
\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
        @tid the created thread ID
        @attr specifies some thread's attributes
        @body is a pointer to the thread body
        @args is passed to the thread body upon execution
        @return 0 if no error occurred 
    */
    int *pthread_create(pthread_t *tid, pthread_attr_t *attr,
    void*(*body)(void*),void *arg);
\end{lstlisting}

Each thread is identified by a unique thread ID (TID).
The current thread TID can be obtained by invoking 
\begin{lstlisting}[language=C]
    #include <pthread.h>
    pthread_t *pthread_self(void);
\end{lstlisting}
Two TIDs can be compared by invoking:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int *pthread_equal(pthread_t id1, pthread_t id2);
\end{lstlisting}

thread attributes specified in \texttt{attr} control some characteristics of the created threads such as: stack size (and address), detach state (joinable or detached), some scheduling parameters (priority,\dots).\\
Thread attributes must be initialized and destroyed:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_attr_init(pthread_attr_t *attr);
    int pthread_attr_destroy(pthread_attr_t *attr);
\end{lstlisting}


Thread can terminate by invoking \texttt{pthread\_exit()}
\begin{lstlisting}[language=C]
    #include <pthread.h>
    void pthread_exit(void *retval);
\end{lstlisting}
A thread can also terminate when its body returns: if the thread is not the main thread \texttt{pthread\_exit()} is automatically called, if the thread is the main thread \texttt{exit()} is called.\\
Of course if the main thread terminates, the process terminates.

Thread can wait for another thread's termiantion by
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_join(pthread_t id, void **result);
\end{lstlisting}
Terminated thread's return value is returned in \texttt{result} (\texttt{*result == PTHREAD\_CANCELED} if the thread was killed)

Every thread should be joined:
\begin{itemize}
    \item The private resources of a terminated thread are not freed until joined (think about memory leak)
    \item Similar to \texttt{wait()} on child processes (think about zombies)
\end{itemize}

A thread that won't be joined must be detached: when a detached thread terminates its resources are immediately released.
There are two ways to detach a thread:
\begin{itemize}
    \item Detach it at creation by \texttt{attr} parameter. Setting \texttt{attr} is performed using \texttt{pthread\_attr\_setdetachstate()}
    \item Detach it after creation by calling \texttt{pthread\_detach()}
\end{itemize}
Joining a detached thread results in an error.

A thread terminates by:
\begin{itemize}
    \item Returning from the body
    \item Calling \texttt{pthread\_exit()}
    \item Killed by other threads using
    \begin{lstlisting}[language=C]
        #include <pthread.h>
        int pthread_cancel(pthread_t tid);
    \end{lstlisting}
    \texttt{tid} is that of the thread to be killed. The function returns 0 if and only if no error occurs.
\end{itemize}

Terminated thread's private resources are released: when the thread is joined (if it is not detached), immediately (if the thread is detached).

Sometimes, killing a thread can leave the system in an inconsistent state (e.g. when settings HW device), so thread cancellation can be deferred until the system state is consistent.

Thread's cancellation si determined by its \side{cancellability state}, consisting of a cencellability type and enable/disable flag.
The cancellability type can be:
\begin{itemize}
    \item \side{Deferred} (default): execute thread cancellation request only at cancellation points, so the thread is canceled only when its state is consisten
    \item \side{Asynchronous}: execute thread cancellation request immediately
\end{itemize}
In order to set the cancellability state's type one can use:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
        PTHREAD_CANCEL_DEFERRED
        PTHREAD_CANCEL_ASYNCHRONOUS
    */
    int pthread_setcanceltype(int type, int *oldtype)
\end{lstlisting}
Whereas the cencallability state's enable/disable is set using:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
        PTHREAD_CANCEL_ENABLE
        PTHREAD_CANCEL_DISABLE // All cancellation requests, regardless of type, are queued until cancellability is enabled again
    */
    int pthread_setcancelstate(int state, int *oldstate)
\end{lstlisting}

With \texttt{PTHREAD\_CANCEL\_DEFERRED}, cancellation request terminates thread only at cancellation point. So a cancellation point checks if any cancellation request is pending. A cancellation point can be:
\begin{itemize}
    \item Explicit if thread calls \texttt{pthread\_testcancel()}
    \item Implicit if thread calls: any standard I/O function, \texttt{pthread\_cond\_wait()}, \dots
\end{itemize}

When using \texttt{PTHREAD\_CANCEL\_ASYNCHRONOUS} cancellation request ends thread immediately. When using \texttt{pthread\_cond\_wait()}, pending cancellation request ends thread without releasing the waited cond. Hence, in order to leave the system in a consistent way use \side{cancellation handler}s aka \side{cleanup handler}s.\\
A cleanup handler is a C function with prototype \texttt{void handler(void *)}.\\
It is called when a thread ends (even if it is killed) and it is the last chance to leave everything in order.

Multiple cleanup handlers can be set: the handlers are stacked and called in a LIFO order. In order to stack handler call:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    // @arg is passed to handler upon invocation
    void pthread_cleanup_push(void (*handler)(void*), void *arg);
\end{lstlisting}
To remove an handler call
\begin{lstlisting}[language=C]
    #include <pthread.h>
    // @execute if not equal to 0, popped handler is executed
    void pthread_cleanup_pop(int execute);
\end{lstlisting}
\texttt{pthread\_cleanup\_push()} and \texttt{pthread\_cleanup\_pop()} must be paired lexically (e.g. malloc and free)

Thread can set its scheduling policy and parameters by specifying them in \texttt{pthread\_create()}'s \texttt{attr}. This is done using the functions:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy);
    int pthread_attr_setschedparam(pthread_attr_t *attr, const struct sched_param *param);
\end{lstlisting}

The only field \texttt{sched\_priority} matters in \texttt{struct sched\_param}.
In addition the attribute:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
        PTHREAD_INHERIT_SCHED  inherit creating thread's policy and parameters 
        PTHREAD_EXPLICIT_SCHED 
    */
    int pthread_attr_setinheritsched(pthread_attr_t *attr, int inheritsched);
\end{lstlisting}

Default \texttt{inheritsched} cannot be assumed (it is implementation-dependent)

\section{Thread Synchronization}
Threads avoid IPC by sharing private resources, trading reliability for speed. So the natural way to synchronize threads is by using the shared resources paradigm.\\
In particular, there can be two kind of interactions between threads in one process:
\begin{itemize}
    \item Cooperation: when multiple threads need to synchronize to provide one service, such as mailbox, pipeline, \dots\\
    A complex algorithm can be parallelized by splitting it into a set of parallel activities. This is done to simplify programming and to benefit from multi-/many-core architecture.\\
    Every parallel activity is executed in a thread that: works on data produced by another thread, produces data for another thread or works on different parts of shared data structure.\\
    Data/thread not ready for processing/communication can wait by blocking till data/thread's ready, upon which the waiting thread will be unblocked. Cooperation che be achieved using a synchronization mechanism.
    \item Competition: when different threads use a shared resource that can be used only by one thread at a time.\\
    A shared resource is usable by 1 thread at a time. So, it must be accessed in \side{mutual exclusion} (mutex). The code accessing the shared resource is called critical section: only 1 thread shall execute in the critical section. Competition can be achieved using a synchronization mechanism. 
\end{itemize}


\subsection{Posix Condition variables vs Mutex}
\definition{Condition variable}{A condition variable is not a variable in the sense that it does not store a value. Multiple threads can block on the variable, waiting for a signal to arrive. Multiple threads can signal the variable:
\begin{itemize}
    \item If no thread blocks the variable, the signal is lost
    \item If one or more already block the variable, the signal unblocks one or all the threads blocking it
\end{itemize}}

\definition{Mutex}{Object with two states (lock and unlock).\\
Multiple threads can lock a mutex:
\begin{itemize}
    \item Already unlocked: 1 thread is selected to own the mutex and the rest blocks on the mutex
    \item Already locked: they block on the mutex
\end{itemize}
Only mutex's owner can unlock a mutex.
}

Please notice that a condition variable needs a mutex: if a condition variable $c$ is used without mutex, the signal can be lost incorrectly
\begin{itemize}
    \item $B$ waits on $c$ but is preempted before completing the wait by queuing itself on $c$
    \item $A$ sends signal $s$ to $c$. $s$ hits empty queue
    \item $A$ is preempted after completing the sent
    \item $B$ resumes by queueing itself to $c$
    \item $B$ lost $s$, but $B$ already waits before $A$ sends $s$
\end{itemize}
So operations on $c$ can be protected by a mutex $m$.

When a thread $A$ signals a condition variable $c$, $A$ shall already own the associated mutex $m$.
The signal then hits the queue of $c$. If thread $B$ in the queue is chosed for unblocking, some unblocking semantics are possible:
\begin{itemize}
    \item $B$ is dequeued from $c$ and tries to lock $m$ such that $B$ is guaranteed to own $m$ once $A$ unlocks $m$
    \item $B$ is dequeued from $c$, and ownership of $m$ is transferred from $A$ to $B$, blocking $A$ on $m$
    \item $B$ is dequeued from $c$ and tries to lock $m$ without guarantee of ownership once $A$ unlocks $m$
\end{itemize}

A POSIX condition variable si a variable of type \texttt{pthread\_cond\_t}. It must be initialized by \texttt{PTHREAD\_COND\_INITIALIZER} or 
\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
       @attr: NULL for default
       return 0 if and only if init is successful
    */
    int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr); 
\end{lstlisting}
The condition variable is waited by (analogous to \texttt{sigsuspend} in IPC)

\begin{lstlisting}[language=C]
    #include <pthread.h>
    /*
       @mutex: mutex already owned by the caller
    */
    int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); 
\end{lstlisting}
Upon return, caller still owns \texttt{mutex}

It is signaled by (\texttt{mutex} should already be owned)
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_cond_signal(pthread_cond_t *cond); // Unblock 1
    int pthread_cond_broadcast(pthread_cond_t *cond);  // Unblock all
\end{lstlisting}

It is freed by:

\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_cond_destroy(pthread_cond_t *cond); 
\end{lstlisting}

If $N$ threads are waiting for a signal, once signaled:
\begin{itemize}
    \item Scheduling policy determines dequeuing order
    \item Predictable in a uniprocessor system
    \item Not automatically so in a multiprocessor system (but can be made predictable with some schemes)
    \item Dequeue thread(s) synchronously but may run later
    \item Valid without owning related mutex
\end{itemize}

POSIX allows \texttt{pthread\_cond\_signal()} to err:
\begin{itemize}
    \item Sometimes 2 or more threads can be unblocked
    \item Known as spurious wakeup
\end{itemize}

\subsection{Programming practice to avoid deadlock}

Settings:
\begin{itemize}
    \item $\ge 2$ shared resources with mutually exclusive access $S_1,\dots, S_n$
    \item $\ge 2$ threads want to own $S_1,\dots, S_n$ one after another (e.g. to update them atomically)
\end{itemize}
Problem: deadlock
\begin{itemize}
    \item $A$ owns $S_1$ and is about to lock $S_2$
    \item $B$ owns $S_2$ and is about to lock $S_1$
    \item $A$ blocks waiting for $S_2$ forever
    \item $B$ blocks waiting for $S_1$ forever
\end{itemize}
Solution: Every thread must lock $S_1, \dots, S_n$ in one particular order
\begin{itemize}
    \item $A$ owns $S_1$ and is about to lock $S_2$
    \item $B$ is about to lock $S_1$
    \item $A$ owns $S_2$, and $B$ blocks waiting for $S_1$
\end{itemize}

The main problem with conditional variable is that \texttt{pthread\_cond\_wait()} is a cancellation point whereas \texttt{pthread\_mutex\_lock} is not.
If a thread is cancelled while blockign after invoking \texttt{pthread\_cond\_wait()}, its mutex is owned again before terminating, resulting in the thread dying while owning the mutex: as a consequence other threads using it will block forever.
The solution is to use a cleanup handler to unlock the mutex.

Available RT resource sharing protocols:
\begin{itemize}
    \item Priority ceiling (\texttt{PTHREAD\_PRIO\_PROTECT})
    \item Priority inheritance (\texttt{PTHREAD\_PRIO\_INHERIT})
\end{itemize}
Please note that not all implementations support them.

Specify it in \texttt{pthread\_mutex\_init()}'s \texttt{attr} by:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_mutexattr_setprotocol(pthread_mutexattr_t *attr, int protocol); 
\end{lstlisting}

For priority ceiling, specify ceiling priority by:
\begin{lstlisting}[language=C]
    #include <pthread.h>
    int pthread_mutexattr_setpriorityceiling(pthread_mutexattr_t *attr, int priorityceiling); 
\end{lstlisting}
